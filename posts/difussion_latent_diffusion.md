---
title: "Difussion : Latent Diffusion"
date: 2023-02-07
readingTime: 20 
thumbnail: /images/difussion_latent_diffusion/thumbnail.png
tags: [Generative AI, Diffusion, DDPM]
category : [Tech Review]
---



## **High-Resolution Image Synthesis with Latent Diffusion Models**

### Stable Diffusion

ğŸ“„ [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752)

ğŸ”— https://github.com/CompVis/stable-diffusion


Stable Diffusionì˜ ê¸°ë°˜ ë…¼ë¬¸ìœ¼ë¡œ, í•µì‹¬ ê°œë…ì€ ì•„ë˜ì™€ ê°™ë‹¤.

- `Latent Diffusion Model`
- `Cross-Attention based Conditioning`
- `text to image`

pixcelì´ ì•„ë‹Œ latent spaceì—ì„œ diffusionì„ ìˆ˜í–‰í•¨ìœ¼ë¡œì¨ computational costë¥¼ ë§ì´ ì¤„ì˜€ë‹¤. ê·¸ëŸ°ë° ë‚œ ì´ ëª¨ë¸ì´ ë” ë§¤ë ¥ì ì¸ ë¶€ë¶„ì€ cross attentionìœ¼ë¡œ generalí•œ conditioning inputì„ ë°›ì•„ë“¤ ì¼ìˆ˜ ìˆëŠ” êµ¬ì¡°ì˜€ë‹¤ëŠ” ì ì´ë‹¤. ì´ë¡œì¨ text ë¡œë„ gudienceë¥¼ ì¤„ ìˆ˜ ìˆë‹¤ëŠ” ì ì´ ë§¤ìš° ê°ë™ì´ì—ˆë‹¤..

### ğŸ’ Guided Diffusionì´ë€?

Stable Diffusion êµ¬ì¡°ë¥¼ ì´í•´í•˜ë ¤ë©´ ë¨¼ì € Guided(conditional) Diffusionì´ ë¬´ì—‡ì¸ì§€ ì•Œì•„ì•¼í•œë‹¤. 
Sampling ê³¼ì •ì— conditionì„ ë„£ì–´ì„œ ìƒì„±ë˜ëŠ” sampleë“¤ì„ ì˜ë„í•œ ë°©í–¥ìœ¼ë¡œ ìœ ë„í•  ìˆ˜ ìˆëŠ” ë°©ì‹ì´ë‹¤. 
ì¦‰ prior distribution p(x)ì— condition yë¥¼ ì¤˜ì„œ p(x|y)ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ê²ƒì´ë‹¤. Guided diffusionì€ diffusion stepë§ˆë‹¤ condition infoë¥¼ ë°˜ì˜í•˜ëŠ” ë°©ì‹ì´ë¼ ìƒê°í•˜ë©´ ëœë‹¤.

$$
p_{\theta}(x_{0:T}|y) = p_{\theta}(x_T)\Pi_{t=1}^Tp_{\theta}(x_{t-1}|x_t,y)
$$

ì´ ìˆ˜ì‹ êµ¬ì¡° ë•ë¶„ì— í…ìŠ¤íŠ¸ë‚˜ ì´ë¯¸ì§€ ë“±ì˜ ì™¸ë¶€ ì…ë ¥ì„ conditionìœ¼ë¡œ ì¤„ ìˆ˜ ìˆë‹¤.


---


### ğŸ”» Gradient ê´€ì ì˜ Guidance

Diffusion modelì€ SDE(ì¦‰, í™•ë¥  íë¦„)ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.

ê·¸ë˜ì„œ guided diffusion modelì€ $\nabla \log p_{\theta}(x_t|y)$ë¥¼ í•™ìŠµí•´ì•¼ í•œë‹¤.

Bayes Ruleì„ ì ìš©í•˜ë©´ ì•„ë˜ì²˜ëŸ¼ ë¶„ë¦¬ëœë‹¤.

$$
\nabla_{x_t} \log p_{\theta}(x_t|y) = \nabla_{x_t} \log (\frac{p_{\theta}(y|x_t)p(x_t)}{p_{\theta}(y)}) \\ = \nabla_{x_t} \log p_{\theta}(x_t) + \nabla_{x_t} \log p_{\theta}(y|x_t)
$$

ì—¬ê¸°ì„œ ë‘ ë²ˆì§¸ í•­ì— ìŠ¤ì¹¼ë¼ ê°€ì¤‘ì¹˜ Î³ë¥¼ ê³±í•œ ê²ƒì´ ë°”ë¡œ **Classifier Guidance**ì´ë‹¤.

$$
\nabla_{x_t} \log p_{\theta}(x_t|y) =\nabla_{x_t} \log p_{\theta}(x_t) + \gamma \cdot\nabla_{x_t} \log p_{\theta}(y|x_t)
$$


---

### ğŸŒ€ Classifier Free guidance

ğŸ“„ [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598)

Classifierë¥¼ ë³„ë„ë¡œ ì‚¬ìš©í•˜ì§€ ì•Šê³  ê°™ì€ ëª¨ë¸ë¡œ conditionalê³¼ unconditionalì„ ëª¨ë‘ í•™ìŠµí•˜ëŠ” ë°©ì‹ì´ë‹¤.
Bayes Ruleì„ ë‹¤ì‹œ ì ìš©í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ í˜•íƒœë¡œ ì •ë¦¬ëœë‹¤.

$$
\nabla_{x_t} \log p_{\theta}(x_t|y) = (1-\gamma)\nabla_{x_t} \log p_{\theta}(x_t) + \gamma \cdot\nabla_{x_t} \log p_{\theta}(x_t|y)
$$

ì´ ê°œë…ì€ Stable Diffusionì—ì„œë„ ë‹¤ìŒê³¼ ê°™ì´ í™œìš©ëœë‹¤.


$$\tilde{\epsilon}(z_\lambda,c) = (1+w)\epsilon_\theta(z_\lambda,c) - w\epsilon_\theta(z_\lambda)$$

<aside>
ì—¬ê¸°ì„œ unconditional termì€ 0ì„ embedding í•˜ëŠ” ë°©ì‹ ë“±ìœ¼ë¡œ ì²˜ë¦¬í•´ì„œ, `í•˜ë‚˜ì˜ ëª¨ë¸`ë¡œ ëª¨ë‘ ë‹¤ë£° ìˆë„ë¡ `conditionalê³¼ unconditional ì„ ë™ì‹œì— í•™ìŠµ` í•œë‹¤.

</aside>

### â­ Latent Diffusionì˜ conditioning  

> `Classifier free guidance`

Latent Diffusionì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ conditional noise predictionì„ ê³„ì‚°í•œë‹¤.

<figure class="eq">
$$\epsilon_\theta(x_t,c) = s\epsilon_{cond}(x_t,c) + (1-s)\epsilon_{cond}(x_t,c_u)$$
</figure>


ì—¬ê¸°ì„œ $c_u$ëŠ” empty promptì— ëŒ€í•œ ì¡°ê±´(conditional embedding)ì´ê³ , $s$ëŠ” guidance strengthì´ë‹¤.

### ğŸ— Architecture

![Untitled](/images/difussion_latent_diffusion/01.webp)

`CLIP Text`

- Text understanding component for Text Encoding
- Transformer language model

`U-Net` + `Scheduler`

- Information creator (í•µì‹¬ diffusion ì—°ì‚°)
- latent space â‡’ faster

`Autoencoder Decoder`

- Image Decoder : ìµœì¢… latent â‡’ ì´ë¯¸ì§€ ë³µì›

### ğŸšª ë‚˜ê°€ë©°

ë‹¨ìˆœí•œ T2I ëª¨ë¸ì„ ë„˜ì–´ì„œ,
í…ìŠ¤íŠ¸ë¼ëŠ” ì¼ë°˜ì ì¸ ì¡°ê±´ì„ í™œìš©í•´ íš¨ìœ¨ì ìœ¼ë¡œ ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” Latent Diffusionì˜ íŒ¨ëŸ¬ë‹¤ì„ì„ ì •ë¦½í•œ ë…¼ë¬¸ì´ë‹¤.

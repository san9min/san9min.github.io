<!DOCTYPE html>
<html lang="ko"><head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Sangmin Blog | Diffusion : DDPM</title>
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css">
  <link rel="stylesheet" href="../../assets/styles/main.css">
  <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
  <link rel="stylesheet"
     href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">

</head><body>
  <main class="article">
    <h1>Diffusion : DDPM</h1>
    <div class="meta">Jan 15, 2023 · 20 min read</div>
    <img class="hero" src="../../images/Diffusion_DDPM/thumb.jpg" alt="cover image">
    <h2><strong>Denoising Diffusion Probabilistic Models</strong></h2>
<h3>DDPM</h3>
<p><a href="https://arxiv.org/abs/2006.11239">Denoising Diffusion Probabilistic Models</a></p>
<ul>
<li>parameterized Markov chain</li>
<li>trained using variational inference</li>
<li><code>learn to reverse a diffusion process</code></li>
</ul>
<p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1b107a88-b5c8-4fea-80df-50b6b903fdc2/Untitled.png" alt="Untitled"></p>
<p>Diffusion model은 latent variable 모델이다.</p>
<p><strong>latent : a hidden continuous feature space</strong></p>
<p><strong>GOAL</strong></p>
<p>$$
p_{\theta} (x_0) = \int p_{\theta}(x_{0:T})dx_{1:T}
$$</p>
<p>$x_1,..x_T$ 는 latent들이고 data $x_0 \sim q(x_0)$와 같은 dimension을 갖는다.</p>
<blockquote>
<p>data에 <code>noise</code>를 더해가는 것을 <code>forward process</code>
noise로 부터 <code>de-noise</code>해나가는 <code>reverse process</code>라한다.</p>
</blockquote>
<p>우리 model은 이 reverse process를 학습하고 새로운 data를 generation한다.</p>
<h3>Forward Process (diffusion process)</h3>
<p><code>forward process는 Gaussian noise를 더해가는 과정</code></p>
<p>이는 Markov chain으로 formulate할 수 있다. 즉, </p>
<p>$$
q(x_{1:T}|x_0) = \Pi_{t=1}^Tq(x_t|x_{t-1}) 
$$</p>
<p>by Markov chain with step T</p>
<p>Markov chain은 각 step은 오직 직전 step에만 의존함을 의미한다.</p>
<p>$q(x_{1:T})$는 q를 timestep 1부터 T까지 반복해서 가함을 의미하는 notation</p>
<p>$\text {where}$</p>
<p>$$
⁍ 
$$</p>
<p>각 스텝에서 Gaussian noise를 더한다</p>
<p>여기서 $\beta_t$는 variance schedule이고 I가 identity이므로 각 dimension은 같은 std를 갖는다. 상수로 둬도 되고, 시간에 따른 변수로 두어도 된다. 논문에선 higer t로 갈수록 커지는 방향으로 linear하게 두었는데 다른 논문에선 cosine shcedule 이 잘 됐다고 한다.</p>
<p>$\beta_t$를 이용해 scaling한 후 더해주는 이유는 variance가 diverge하는 것을 막기위함으로 볼 수 있다. </p>
<aside>
💡 Gaussian noise를 더해가면, 최종 step (time T)에서는standard normal prior $N(x_T;0,I)$ 가되고 그래서 diffusion이라 한 것같다.

</aside>

<p>그런데 여기서 어떤 순간 t ( $0 \le t \le T)$에서 $x_t$를 알고 싶다고한다면, 위의 식을 이용해 반복적인 계산을 수행하면 된다. 그러나 t 가 크다면 이는 좋은 방법이 아닐 것이다.</p>
<p><strong>Reparameterization trick (for sampling</strong> $x_t$ <strong>at once)</strong></p>
<p>만약 우리가</p>
<p>$\alpha_t = 1-\beta_t , \bar \alpha_t = \Pi_{s=0}^t \alpha_s$ 라고 잡는다면, t에서 $x_t$를 sampling하는 것을 closed form으로 쓸 수 있을 것이다.</p>
<p>⭐⭐⭐</p>
<p>$$
q(x_t|x_0) = N(x_t;\sqrt {\bar \alpha_t} x_0, (1- {\bar \alpha_t})I)
$$</p>
<p>sample = mean + (var**0.5)*epsilon</p>
<p>⭐⭐⭐</p>
<ul>
<li><p><strong>Proof )</strong></p>
<p>  let $\epsilon_0, \cdots \epsilon_{t-2},\epsilon_{t-1} \sim N(0,I)$</p>
<p>  $x_ t = \sqrt{(1-\beta_t)}x_{t-1} + \sqrt {\beta_t} \epsilon_{t-1} \ =\cdots  \=\sqrt{\bar \alpha_t}x_0 + \sqrt{1-\bar{\alpha_t}}\epsilon_0$</p>
<p>  증명의 핵심논리는 다른 variance를 갖는 두개($\sigma_1^2,\sigma_2^2$)의 Gaussians을 merge해 새로운 distribution(with variance $\sigma_1^2+\sigma_2^2$ )을 만드는 것</p>
</li>
</ul>
<p>좋다. </p>
<p>확인을 해보면 t → $\infty$로 갈때 $q(x_t|x_0)$가 $N(x_t;0,I)$로 감도 볼 수 있다</p>
<p>이제 우리는 any timestep t에서 noise를 sampling할 수 있게됐고, 이를 통해 $x_t$를 $x_0$와 $\epsilon$의 함수로 볼수 있게 되어 forward process에서 $x_0$만 알면 바로  <strong>$x_t$를 얻을 수 있게됐다.</strong></p>
<p>$$
x_t = \sqrt{\bar \alpha_t}x_0 + \sqrt{1-\bar{\alpha_t}}\epsilon_0
$$</p>
<p>or</p>
<p>$$
x_0 = \frac{1}{\sqrt{\bar \alpha_t}}(x_t - \sqrt{1-\bar \alpha_t}\epsilon)
$$</p>
<h3>Reverse Process (denoising process)</h3>
<p><code>reverse process는 neural network이 학습할 과정</code></p>
<p>$q(x_{t-1}|x_{t})$를 원하나 어려워서 neural network를 이용</p>
<p>forward process의 Gaussian noise가 충분히작을 때 reverse process 또한 Gaussian이 되고 이는 neural network를 이용해 근사시켜 mean과 variance를 예측하는 모델을 만들 수 있다.</p>
<p>$$
p_{\theta}(x_{t-1}|x_t) = N(x_{t-1};\mu_{\theta}(x_t,t), \Sigma_{\theta}(x_t,t))
$$</p>
<p>Reverse process는 $p(x_T) = N(x_T;0,I)$부터 출발해 (learned) Gaussian trainsition을 하는 Markov chain이다. 즉, trajectory는</p>
<p>$$
⁍
$$</p>
<p>로 fomulate할 수 있다.</p>
<aside>
💡 neural network에 timestep t를 conditioning하면 model은 각 time step의 Gaussian의 mean과 variance를 예측할 수 있게된다.

</aside>

<h3>Training</h3>
<p><code>ELBO</code>on the negative log likelihood를 optimize</p>
<p>$$
E[-\log p_{\theta}(x_0)] \le E_q[-\log \frac {p_\theta (x_{0:T})}{q(x_{1:T}|x_0)}] \ = L
$$</p>
<p>이고 위 식을 정리하면</p>
<p>$$
L = E_q[D_{KL}(q(x_T|x_0)||p(x_T))+\sum_{t&gt;1}D_{KL}(q(x_{t-1}|x_t,x_0)||p_{\theta}(x_{t-1}|x_t))-\log p_{\theta}(x_0|x_1)]
$$</p>
<p>이 된다.</p>
<aside>
💡 $q(x_{t-1}|x_t)$는 intractable하지만 $x_0$의 conditioning을 주면 tractable하다고 함 → generative model이 reverse diffusion step으로 generation을 하기 위해선 reference image $x_0$가 필요하다

</aside>

<p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d411bb47-dcf7-4b5a-afb1-89eb1e580dcc/Untitled.png" alt="Untitled"></p>
<blockquote>
<p>동하 주)</p>
<ul>
<li><p>위 식 증명 과정</p>
<p>  $q(x_{t-1}|x_t)$는 무시가능해짐. (Markov Process이기 때문)</p>
<p>  <img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c052df61-f676-421a-b570-5f8733d6d4d0/Untitled.png" alt="Untitled"></p>
</li>
</ul>
</blockquote>
<p>결국 하고 싶은 것은 <code>$p_{\theta}(x_{t-1}|x_t)$와 forward process posteriors $q(x_{t-1}|x_t,x_0)$를 비교</code>하는 것이고</p>
<p>$L_T = D_{KL}(q(x_T|x_0)||p(x_T))$ = const</p>
<p>$X_T$가 얼마나 standard Gaussian인지, 그런데 우리는 $\beta_t$를 시간에 따른 constant 로 두었으므로 이 term도 constant이고 학습할 때 <code>무시</code>해도 된다</p>
<p>$L_{T-1} = \sum_{t&gt;1}D_{KL}(q(x_{t-1}|x_t,x_0)||p_{\theta}(x_{t-1}|x_t))$</p>
<p>denoising step $p_{\theta}(x_{t-1}|x_t)$ 과 approximated denoising step $q(x_{t-1}|x_t,x_0)$간의 차이를 계산함을 볼 수 있음</p>
<p>model이 <code>noise를 예측</code>하도록 <code>Reparam</code></p>
<ol>
<li>$\Sigma_{\theta}(x_t,t) = \sigma_t^2I$, $\sigma$는 $\beta$에 관한 time dependent constants</li>
<li>$\mu_\theta(x_t,t)$ for $p_{\theta}(x_{t-1}|x_t)$ using  $x_t(x_0,\epsilon)$</li>
</ol>
<p>⭐⭐⭐</p>
<p>$$
p_\theta(x_{t-1}|x_t) = N(x_{t-1};\mu_{\theta}(x_t,t),\sigma_t^2I)
$$</p>
<p>$$
\mu_{\theta}(x_t,t) = \frac 1 {\sqrt {\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar \alpha_t}}\epsilon_{\theta}(x_t,t))
$$</p>
<p><strong>sample</strong> $x_{t-1}$ = $\frac 1 {\sqrt {\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar \alpha_t}}\epsilon_{\theta}(x_t,t))$ + $\sigma_t$<strong>z</strong>,      <strong>z</strong> $\sim N(0,I)$</p>
<p>⭐⭐⭐</p>
<p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b1b82858-adcf-4e8f-8ee0-b4fb748bd636/Untitled.png" alt="Untitled"></p>
<p>⇒<code>$\epsilon_{\theta}$ 는 $x_t$와 t를 받고 noise를 예측</code>한다.</p>
<p>$x_t$는 $x_0$로 부터 sampling이 가능하도록 위에서 reparam했다.</p>
<p>$L_0 = -\log p_{\theta}(x_0|x_1)$</p>
<p><code>Reconstruction term</code></p>
<p>⭐⭐⭐</p>
<p><strong>Simplified Loss</strong></p>
<p>$$
L_{simple}(\theta) = \mathbb E_{t,x_0,\epsilon} [||\epsilon -\epsilon_{\theta}(\sqrt{\bar \alpha_t}x_0  + \sqrt{1-\bar\alpha_t}\epsilon,t) ||^2]
$$</p>
<p>⭐⭐⭐</p>
<p>t = 1 일 때</p>
<p>$L_0$ 즉, $-\log p_{\theta}(x_0|x_1)$를 minimize</p>
<p>t&gt; 1일 때</p>
<p>$L_{t-1}$에서 식 정리하면 나오는 coefficient $\frac{\beta_t^2}{2\sigma_t^2\alpha_t(1-\bar\alpha_t)}$를 버려서 higher noise level(higer t)에 전(coefficient 가 있을 때)보다 더 큰 weight를 주고 small t에 대해선 더 작은 weight를 줘서 더 좋은 sample quality를 얻었다. (small t에선 model이 작은 양의 noise만 denoise하도록 학습을 시키기 때문, 그래서 더 어려운 large t에 집중하도록 만듦)</p>
<p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/9f379455-4bf7-4088-a3fa-49fa0bda4539/Untitled.png" alt="Untitled"></p>
<aside>
💡 random하게 timesteps t를 뽑고, $x_0$와 t를 이용해 $q(x_t|x_0)$ 로부터 $x_t$를 구함
이 $x_t$와 t를 우리 모델에 넣고 epsilon을 뽑음
이 epsilon과 ($x_0$와 정확히 같은 dimension을 갖는) noise를 뽑고 MSE loss 때리면 됨

</aside>

<h3>Model Architectue</h3>
<p>model의 input과 output의 dimension이 같아야한다. 본 논문에선 U-Net을 사용했다. U-Net은 Residual Block, self-attention block이 있다.</p>
<p>diffusion의 timestep t가 position embedding을 한 후residual block에 전달되는 식으로 모델에 t가 입력된다.</p>
<p><strong>U-Net</strong></p>
<p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/22fdc1ea-d205-47fe-9d1f-a9715d5f4c05/Untitled.png" alt="Untitled"></p>
<p>$\epsilon_{\theta}$ <strong>model using U-Net</strong></p>
<p>input <code>$(x_t, t)$</code></p>
<p>output <code>noise</code></p>
<p>제거해야할 noise</p>
<p><strong>Implementation Code</strong></p>
<pre><code class="language-python">TODO
Skeleton code 작성해보기
</code></pre>

    <section class="related">
        <div class="related-head">
          <h2>Related posts</h2>
          <a class="all-link" href="../../">Browse all articles&nbsp;→</a>
        </div>
        <div class="related-list">
      <a class="card mini" href="../../posts/Diffusion_DDIM/">
        <img class="thumb" src="../../images/post-002-thumb.jpg" alt="">
        <div class="card-body">
        
          <h3 class="card-title">Diffusion : DDIM</h3>
          <span class="arrow">↗</span>
          <div class="meta">Feb 17, 2025 · 20 min</div>
        </div>
      </a>
      <a class="card mini" href="../../posts/RL_Asynchronous Methods for Deep Reinforcement Learning/">
        <img class="thumb" src="../../images/RL_Asynchronous_Methods_for_Deep_Reinforcement_Learning/thumb.png" alt="">
        <div class="card-body">
        
          <h3 class="card-title">Reinforcement Learning : Asynchronous Methods for Deep Reinforcement Learning</h3>
          <span class="arrow">↗</span>
          <div class="meta">Feb 17, 2025 · 20 min</div>
        </div>
      </a>
      <a class="card mini" href="../../posts/Difussion_Latent Diffusion/">
        <img class="thumb" src="../../images/latentdiffusion.webp" alt="">
        <div class="card-body">
        
          <h3 class="card-title">Difussion : Latent Diffusion</h3>
          <span class="arrow">↗</span>
          <div class="meta">Feb 17, 2024 · 20 min</div>
        </div>
      </a></div>
      </section> 
  </main>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
<script>
window.MathJax = {
  tex: {
    inlineMath:  [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
    processEnvironments: true
  },

  chtml: {
    linebreaks: { automatic: true, width: "match" }  // 또는 width: 80
  },

  options: {
    renderActions: { addMenu: [] }   // 우클릭 메뉴 제거
  }
};
</script>
<script id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  <script src="../../assets/js/main.js" defer></script>
</body></html>